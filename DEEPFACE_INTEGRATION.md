# üé≠ Integraci√≥n de DeepFace (Modelo Local)

Este documento explica c√≥mo usar el modelo local de DeepFace en lugar de OpenAI para la detecci√≥n de emociones.

## üéØ Ventajas del Modelo Local

‚úÖ **100% Privado**: Todo el procesamiento ocurre localmente, sin enviar im√°genes a servicios externos.

‚úÖ **Sin Costos**: No requiere API keys ni pagos por uso.

‚úÖ **M√°s R√°pido**: Sin latencia de red externa, solo comunicaci√≥n local.

‚úÖ **Control Total**: Puedes ajustar el modelo, umbrales y par√°metros.

‚úÖ **Offline**: Funciona sin conexi√≥n a internet.

## üìã Requisitos

### Hardware
- **CPU**: Dual-core 2.0 GHz o superior
- **RAM**: 4 GB m√≠nimo, 8 GB recomendado
- **GPU** (Opcional, para mayor velocidad):
  - Mac: Apple Silicon (M1/M2/M3)
  - Windows/Linux: NVIDIA con CUDA

### Software
- **Python**: 3.8 - 3.10
- **Node.js**: 18+
- **Webcam**: Integrada o externa

## üöÄ Instalaci√≥n

### 1. Instalar Dependencias Python

```bash
cd model

# Crear entorno virtual (recomendado)
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements_api.txt
```

#### Para Mac con Apple Silicon (M1/M2/M3)

Edita `requirements_api.txt` y descomenta las l√≠neas de TensorFlow Metal:

```txt
tensorflow-macos==2.16.2
tensorflow-metal==1.1.0
```

Luego instala:

```bash
pip install -r requirements_api.txt
```

#### Para GPU NVIDIA

Descomenta en `requirements_api.txt`:

```txt
tensorflow==2.16.2
```

Y aseg√∫rate de tener CUDA instalado.

### 2. Iniciar el Servidor API

```bash
# En Mac/Linux
cd model
chmod +x start_api.sh
./start_api.sh

# En Windows
cd model
start_api.bat
```

O manualmente:

```bash
cd model
python api_server.py
```

Deber√≠as ver:

```
üöÄ Starting Emotion Detection API...
üìä Using DeepFace model
üåê Server will be available at http://localhost:8000
üìö Docs at http://localhost:8000/docs
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 3. Configurar el Frontend

Actualiza el archivo `.env` en la ra√≠z del proyecto:

```bash
# Para usar DeepFace (modelo local)
VITE_API_ENDPOINT=http://localhost:8000/api/analyze-emotion
VITE_USE_DEEPFACE=true

# Otros par√°metros
VITE_TARGET_FPS=15
VITE_SMOOTHING_WINDOW=2.5
```

### 4. Actualizar el Worker

Edita `src/infrastructure/workers/emotion-worker.ts` para usar DeepFace:

```typescript
import { DeepFaceEmotionService } from '../services/DeepFaceEmotionService';

// ... en el handler de INIT:
detector = new DeepFaceEmotionService(); // En lugar de OpenAIEmotionService
```

## üîÑ Cambiar Entre Modelos

El proyecto usa arquitectura DDD, por lo que cambiar entre modelos es f√°cil:

### Usar DeepFace (Local)

```typescript
// src/infrastructure/workers/emotion-worker.ts
import { DeepFaceEmotionService } from '../services/DeepFaceEmotionService';

detector = new DeepFaceEmotionService();
```

### Usar OpenAI (Remoto)

```typescript
// src/infrastructure/workers/emotion-worker.ts
import { OpenAIEmotionService } from '../services/OpenAIEmotionService';

detector = new OpenAIEmotionService();
```

## üéØ Modelo DeepFace: Detalles T√©cnicos

### Emociones Detectadas

DeepFace detecta 7 emociones b√°sicas:

1. **Angry** (Enojado) üò†
2. **Disgust** (Disgusto) ü§¢
3. **Fear** (Miedo) üò®
4. **Happy** (Feliz) üòä
5. **Sad** (Triste) üò¢
6. **Surprise** (Sorpresa) üò≤
7. **Neutral** (Neutral) üòê

### Conversi√≥n a Valencia/Arousal

El servicio convierte estas emociones al espacio dimensional Valencia-Arousal:

**Valencia** (Positivo/Negativo: -1 a 1):
- `happy`: +1.0 (muy positivo)
- `neutral`: 0.0
- `surprise`: +0.2
- `sad`: -0.7
- `angry`: -1.0 (muy negativo)
- `fear`: -0.8
- `disgust`: -0.9

**Arousal** (Activaci√≥n: 0 a 1):
- `angry`: 0.95 (muy activado)
- `fear`: 0.90
- `surprise`: 0.75
- `happy`: 0.70
- `disgust`: 0.45
- `sad`: 0.30
- `neutral`: 0.20 (poco activado)

### C√°lculo de Estr√©s

El nivel de estr√©s se calcula bas√°ndose en:

**Aumentan el estr√©s** (emociones negativas):
- `angry` √ó 1.5
- `fear` √ó 1.3
- `sad` √ó 0.8
- `disgust` √ó 1.0

**Reducen el estr√©s** (emociones positivas):
- `happy` √ó 2.0
- `neutral` √ó 0.5

F√≥rmula:
```
stress = 50 + (stress_emotions √ó 0.5) - (calm_emotions √ó 0.3)
```

Resultado: 0-100 (% de estr√©s)

## üìä Rendimiento

### Tiempos T√≠picos

| Hardware | Tiempo por Frame | FPS M√°ximo |
|----------|-----------------|------------|
| CPU (Intel i5) | ~150-200ms | 5-7 FPS |
| Apple M1/M2 | ~50-80ms | 12-15 FPS |
| NVIDIA GPU | ~30-50ms | 15-20 FPS |

### Optimizaciones Aplicadas

1. **Detector r√°pido**: Usa `opencv` backend (m√°s r√°pido que `retinaface`)
2. **Sin detecci√≥n estricta**: `enforce_detection=False` evita errores si no hay cara
3. **Cach√© del modelo**: Se carga una sola vez al inicio
4. **Compresi√≥n de imagen**: JPEG con quality 0.8 reduce tama√±o de transferencia

## üîß Troubleshooting

### El servidor no inicia

**Error**: `ModuleNotFoundError: No module named 'fastapi'`

**Soluci√≥n**:
```bash
cd model
pip install -r requirements_api.txt
```

### TensorFlow no detecta GPU

**Mac con Apple Silicon**:
```bash
pip uninstall tensorflow
pip install tensorflow-macos tensorflow-metal
```

**Verificar GPU**:
```python
import tensorflow as tf
print("GPU available:", len(tf.config.list_physical_devices('GPU')) > 0)
```

### Error de CORS

**Error**: `Access to fetch at 'http://localhost:8000' from origin 'http://localhost:3000' has been blocked by CORS policy`

**Soluci√≥n**: El servidor ya tiene CORS habilitado. Verifica que el servidor est√© corriendo en el puerto correcto.

### Detecci√≥n lenta

1. **Baja la resoluci√≥n** del video:
```typescript
// src/infrastructure/services/CameraService.ts
const constraints = {
  video: {
    width: { ideal: 480 },  // M√°s bajo = m√°s r√°pido
    height: { ideal: 360 },
    frameRate: { ideal: 15 }
  }
};
```

2. **Aumenta el intervalo** entre frames:
```env
VITE_TARGET_FPS=10  # Procesar menos frames por segundo
```

3. **Usa GPU** si est√° disponible

### No se detecta cara

DeepFace funciona mejor con:
- Iluminaci√≥n frontal adecuada
- Cara visible y sin oclusiones
- Distancia media de la c√°mara (50-100cm)

## üéÆ Uso

Una vez que el servidor API est√© corriendo y el frontend configurado:

1. **Inicia el servidor API** (en una terminal):
   ```bash
   cd model
   python api_server.py
   ```

2. **Inicia el frontend** (en otra terminal):
   ```bash
   npm run dev
   ```

3. **Abre el navegador** en `http://localhost:3000`

4. **Activa la c√°mara** y el sistema comenzar√° a detectar emociones localmente

## üìà Comparaci√≥n: DeepFace vs OpenAI

| Caracter√≠stica | DeepFace (Local) | OpenAI GPT-4 Vision |
|---------------|------------------|---------------------|
| **Privacidad** | ‚úÖ 100% local | ‚ö†Ô∏è Env√≠a a OpenAI |
| **Costo** | ‚úÖ Gratis | ‚ùå $0.01 por imagen |
| **Velocidad** | ‚úÖ 50-200ms | ‚ö†Ô∏è 500-2000ms |
| **Offline** | ‚úÖ S√≠ | ‚ùå No |
| **Precisi√≥n** | ‚ö†Ô∏è Buena | ‚úÖ Excelente |
| **Contexto** | ‚ùå Solo cara | ‚úÖ Escena completa |
| **Setup** | ‚ö†Ô∏è Requiere Python | ‚úÖ Solo API key |

## üîÆ Pr√≥ximas Mejoras

- [ ] Suavizado temporal acumulativo (como en `main.py`)
- [ ] Detecci√≥n de calidad (luz, desenfoque)
- [ ] Historial de emociones con gr√°ficos
- [ ] Exportaci√≥n de datos a CSV
- [ ] Calibraci√≥n de baseline neutral
- [ ] Soporte para m√∫ltiples caras

## üìö Referencias

- [DeepFace GitHub](https://github.com/serengil/deepface)
- [Russell's Circumplex Model](https://en.wikipedia.org/wiki/Emotion_classification#Circumplex_model)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

